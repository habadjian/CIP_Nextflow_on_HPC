# ðŸ‘‹ Welcome to the Instructional Intro to Nextflow on HPC
This repository is designed to be an interactive introduction on how to use Nextflow on HPC within the CIP.



This intro assumes that you are familiar with a <a href="https://en.wikipedia.org/wiki/Linux" target="_blank">Linux Operating System</a> and are proficient in using Linux command line tools.


This tutorial was created with the San Diego Supercomputer Center's Expanse supercomputer in mind.


## âœ” Mission Objectives
After completing this introduction, you should:
1. Be able to run a simple Nextflow pipeline on HPC
2. How to use conda environments with Nextflow
3. How to use Nextflow with Singularity containers
4. Perform simple data analysis and visualizations 
5. Be able to use basic git commands

# Why Nextflow on HPC with Slurm?

- **Accessibility**: Nextflow abstracts the complexities of SLURM, making it more accessible and user-friendly.
- **Simplified Workflow Management**: Users can define and execute workflows using simple, high-level commands.
- **Efficient Execution**: Facilitates the efficient and scalable execution of complex data analysis pipelines.
- **No In-depth SLURM Knowledge Required**: Allows leveraging SLURM's powerful resource management capabilities without needing detailed knowledge of its configurations.
- **Optimized Resource Utilization**: Ensures optimal utilization of HPC resources by integrating workflow management with SLURM's job scheduling.
- **Enhanced Workflow Development**: Simplifies the overall workflow development and execution process.



# General Guide

[Very Basic Guide](basic_guide.md)


# Nextflow setup on cluster

Unfortunately, there are instances where Nextflow is not available on the cluster and must be installed manually.

[Nextflow setup on cluster](nextflow_setup.md)

# Before moving onto Nextflow examples that utilize SLURM, let's do very simple SLURM example tutorials

