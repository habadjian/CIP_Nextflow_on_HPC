params {
  config_profile_description = 'adapting beowulf conf to SDSC expanse'
  config_profile_url = 'https://hpc.nih.gov/apps/nextflow.html'
  max_memory = '224 GB'
  max_cpus = 32
  max_time = '72 h'
  project = '<<EXPANSEPROJECT>>'
  partition = 'compute'
  cluster_user = System.getenv('USER')
}









// use a local executor for short jobs and it has to give -c and --mem to make nextflow
// allocate the resource automatically. For this the
// settings below may have to be adapted to the allocation for
// the main nextflow job.


profiles {
    expanselocal {
        process {
            executor = 'local'
            cache = 'lenient'
            maxRetries = 3
            queueSize = 100
            memory = "$SLURM_MEM_PER_NODE"
            cpus = "$SLURM_CPUS_PER_TASK"
       }
    }

    expanse {

        //-- * https://www.sdsc.edu/support/user_guides/expanse.html
        //-- * max running jobs on shared is 4096
        executor {
            queueSize = 500
        }



        //-- ! This makes sure that $HOME folder is not being used, and Expanse users won't be angry at you.
        workDir = "/expanse/lustre/projects/${params.project}/${params.cluster_user}/CIP_examples/example1_workdir"

        process {
            executor = 'slurm'
            maxRetries = 1
            queue = params.partition
            queueSize = 200
            pollInterval = '2 min'
            queueStatInterval = '5 min'
            submitRateLimit = '6/1min'
            retry.maxAttempts = 1

            clusterOptions = ' --export=ALL --nodes=1 --ntasks-per-node=1 -t 00:55:00 -A $params.project '

            scratch = '/scratch/$USER/job_$SLURM_JOB_ID'
        
        withLabel:very_low_cpu{
          cpus = 1
          memory = '512 MB'
          time = '3 h'
          queue = 'shared'
          queueSize = 500
          pollInterval = '2 min'
          queueStatInterval = '5 min'
          submitRateLimit = '6/1min'
          retry.maxAttempts = 1
          clusterOptions = " --export=ALL --nodes=1 --ntasks-per-node=10 -A $params.project "
        }


        //-- * This makes processes associated with low_cpu label to use only 1 core and 512MB ram
        withLabel:low_cpu{
          cpus = 1
          memory = '512 MB'
          time = '1 h'
          queue = 'compute'
          clusterOptions = " --export=ALL --nodes=1 --ntasks-per-node=1 -t 00:55:00 -A $params.project "
        }

     }
        timeline.enabled = true
        report.enabled = true
        report.overwrite = true
    }
}


//-- mail {
//    smtp.host = 
//    smtp.port = 
//    smtp.user = 
//    smtp.password = 
//    smtp.auth = true
//}


