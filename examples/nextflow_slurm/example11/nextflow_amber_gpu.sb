#!/bin/bash
#SBATCH --job-name="nf_amber"
#SBATCH --output="nf_amber.%j.%N.out"
#SBATCH --partition=shared
####SBATCH --partition=debug
#SBATCH --export=ALL
#SBATCH -t 05:00:00
#SBATCH -A sds196
#SBATCH --mem 2000M
#SBATCH --cpus-per-task=2
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1

##  Load module file(s) into the shell environment


##-- * This is for GPU amber
module purge --force
# module load cpu/0.15.4
module load  gpu/0.15.4  
module load openmpi/4.0.4
module load slurm
module load amber/20-patch15
module load anaconda3/2020.11
eval "$(conda shell.bash hook)"


eval "$(conda shell.bash hook)"
##  just perform some basic unix commands

# Run python script
conda activate /home/$USER/a/conda_envs/nextflow
export NFX_OPTS="-Xms=512m -Xmx=4g"
nextflow -C ~/a/CIP_Nextflow_on_HPC/examples/nextflow_slurm/example11/nextflow.config  \
    run -profile expanse ~/a/CIP_Nextflow_on_HPC/examples/nextflow_slurm/example11/test.nf  \
    -params-file ~/a/CIP_Nextflow_on_HPC/examples/nextflow_slurm/example11/config.yml  \
    -resume -with-conda true \
    --outdir ~/a/CIP_Nextflow_on_HPC/examples/nextflow_slurm/example11/example11_workdir
